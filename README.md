# 简单爬虫工具

一个为实验室项目服务的多平台数据爬取工具集（并不完整），支持部分主流社交媒体平台的内容和评论爬取。

## 功能概览

| 平台 | 可爬取帖子 | 可爬取评论 | 使用基础方法 | 使用外部API | 数据简单清洗 |
|------|-----------|-----------|-------------|-------------|-------------|
| 微博 | ✅ | ✅ | ✅ | ❌ | ✅ |
| 知乎 | ✅ | ✅ | ✅ | ❌ | ✅ |
| 小红书 | ❌ | ❌ | ❌ | ❌ | ✅ |
| 抖音 | ✅ | ❌ | ❌ | ✅ | ✅ |
| 微信公众号 | ✅ | ✅ | ❌ | ✅ | ✅ |

## 技术方案

### 基础方法
使用 `selenium` 和 `requests` 等常规爬虫库，通过模拟浏览器行为和API请求获取数据。

### 外部API
主要使用 [TikHub API](https://tikhub.io/) 服务，提供稳定的数据接口支持。

## 项目结构

```
├── weibo/          # 微博爬虫模块
├── zhihu/          # 知乎爬虫模块  
├── xhs/            # 小红书爬虫模块
├── douyin/         # 抖音爬虫模块
└── weixin/         # 微信公众号爬虫模块
```

## 主要功能

### 数据爬取
- **关键词搜索**: 支持基于关键词的内容搜索和爬取
- **帖子详情**: 获取帖子的详细内容、作者信息、发布时间等
- **评论数据**: 爬取帖子下的评论及回复信息

### 数据处理
- **数据清洗**: 去重、格式化、数据验证
- **数据合并**: 多个数据源的整合处理  
- **格式转换**: 支持JSON、CSV等多种输出格式
- **时间标准化**: 统一时间戳格式处理

## 环境配置

1. 安装依赖包：

```bash
pip install selenium requests pandas beautifulsoup4 python-dotenv
```

2. 配置环境变量（创建 `.env` 文件）：

```
TIKHUB_API_KEY=your_api_key_here
```

3. 下载对应浏览器驱动（如需要使用selenium）

## 使用说明

基础方法一般包含以下核心文件：

- `crawl_keywords.py` - 关键词搜索，基于selenium，一般最先使用以获取url
- `crawl_body.py` - 帖子内容爬虫  
- `crawl_comments.py` - 评论爬虫
- `clean_data.py` - 数据清洗工具
- `**_cookie.json` - requests需要的一些参数，不同网站的按名称替换**，内容可参考`weibo_cookie_sample.json`

调取api的方法建议自行前往对应网页探索

具体使用方法请参考各模块内的示例代码。

## 注意事项

- 请遵守各平台的robots.txt和使用条款
- 合理控制爬取频率，避免对服务器造成压力
- 仅用于学术研究和实验室项目
- 使用外部API时注意配额限制

## 免责声明

首先，本工具的作者水平较低，不建议使用😭

### 法律合规

本工具仅供学术研究和教育目的使用，使用者在使用本工具时应当：

- 严格遵守中华人民共和国相关法律法规
- 遵守目标网站的robots.txt协议和使用条款
- 尊重网站的版权和知识产权
- 不得用于商业用途或非法目的

### 技术限制

- 本工具可能随时因目标网站更新而失效
- 不保证数据的完整性和准确性
- 可能存在技术缺陷和安全风险

### 使用责任

使用者应当：

- 合理控制爬取频率，避免对目标服务器造成过大压力
- 自行承担因使用本工具而产生的任何法律责任
- 在使用前充分了解相关法律法规和平台政策
- 对获取的数据承担保密和合规使用责任

### 数据使用

- 获取的数据仅可用于学术研究
- 禁止传播、售卖或用于其他商业目的
- 涉及个人隐私的数据应当妥善处理
- 研究成果发布时应当保护数据主体隐私

### 其他说明

- 本工具作者不承担任何直接或间接的法律责任
- 使用本工具即表示同意承担相关风险
- 如有疑问，请咨询相关法律专业人士

**重要提醒：在使用任何爬虫工具前，请务必了解并遵守相关法律法规！**